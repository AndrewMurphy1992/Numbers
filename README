WARNING: I AM NOT RESPONSIBLE FOR YOUR LOST DATA, OR MISUSE OF AI. KEEP BACKUPS OF ANY FILES YOU USE THIS '3/4-MIRROR-CIPHER' ON. THIS IS A PRE-BETA PROGRAM AND ANY DATA YOU CODE THIS WAY IS VERY LIKELY TO BE CORRUPTED AND LOST FOREVER, OPTIMIZATIONS HAVE NOT BEEN MADE, AND IT IS NOT YET A DEPENDABLE PRODUCT. YOU HAVE BEEN WARNED.

Something that I've noticed is that AI is *incredibly* bad at math. No offence to the developers out there, I absolutely love you and the machines you have trained. However, there are some major flaws in the current approach that everyone seems to be using. First, even though AI can now write code, it fails to employ any code which it can write. For example, if you ask an AI to generate a number in a base system of great size, it will generally fail to do so correctly, even though it lists out all the right steps to do so. A simple solution is to give the Ai access to byte code so that it can compile and run the scripts that it writes. Then it has a calculator running on bare-metal, and it won't make the same mistakes when asked. A more interesting solution, is to provide the AI with a virtual machine environment that has certain rules which make it impossible to make certain mistakes. For example, one could write a system of nested files and use the python 'os' module to give an AI on your machine the ability to navigate directories based on certain instructions. Built into these folders are text documents which the AI is required to access to receive a 'bit key.' Each folder represents the ouput of a logic gate. It uses that bit key to navigate the folders and comes out with the desired outputs as they might be represented by an led on a breadboard. I put an example FULL ADDER together this way in the repository labeled AI-Powered-Operating-System. Training an Ai in an environment like this, even a more extensive environment like a whole ALU, entire CPU, etc, may give Ai the tools to perform extremely simple logical operations SEMANTICALLY, which it is not currently capable of doing with any degree of reliablility. Semantic fluency will give AI a big boost in how well it reads, writes, and 'rithmatics. 

Ok so in this portion of the pre-codec, we have a very specific problem that we would like to solve using a particular technique. Whereas in the general pre-codec that everything will go into later there is a 'latice' technique for isolating all but 1 number from the trailing positions in a 'modified_character', and the trained decoder will have specific knowledge on small words or words that may be numbers, the primary technique in this 'pre-codec' will be providing 'categorization_clues' based on manipulating large (int) and their related (str). In the main program you will notice that if you provide an AI with the numbers in order as a kind of key along with the word key and possibly the huffman code header, it will decode the ambiguous pre-coded document perfectly. (It will even do this without any key at all!) Unfortunately, in documents that consist mostly of numbers this does not improve compression, but reduces it by half (pretty funny). So, in order to solve this we will apply a similar principle to the main program -- the numbers will be narrowed down using a code which provides the AI with a sort of "game". The pre-coder will provide the AI with a variety of boolean flags with associated conditionals, generated by a regular program. It will then write them into a 'number_key' which is packaged with the rest of the pre-coded document. The AI will have access to an API which contains the definitions of the flags and associated conditionals. You can think of this in terms of assembly code, with the AI acting as a type of softened-hardware, or 'Virtualized Transistor-Like Environment', if you will. This will be capable of helping reduce the size of files containing mostly numbers when used in conjunction with conventional compression, and can then be incorporated into the main program. 

Foresight: Likely, compression will be limited to 'blocks' at a time, of a certain size, because of hardware limitations and also the current limitations of AI itself. This is also an area that will probably require signifigant debugging before it could be considered a mission-critical way to compress and retrieve numbers. Still, it should be easily possible to reliably decompress numerical data using machine inference, given the correct process of elimination. It is finding a process that works 100% of the time that we are searching for here. 

Update: Implementing feedback loop into number.key. when decrypting the document, the AI can determine where some of the numbers go based on the context of the document. It can then extend the truth table to a signifigant extent in some cases. It will have 'set' the pins inbetween the keyway and cylinder, so to speak. It can succesfully narrow down the possible number much more easily when any given integer is certain. 
