WARNING: I AM NOT RESPONSIBLE FOR YOUR LOST DATA, OR MISUSE OF AI. KEEP BACKUPS OF ANY FILES YOU USE THIS '3/4-MIRROR-CIPHER' ON. THIS IS A PRE-BETA PROGRAM AND ANY DATA YOU CODE THIS WAY IS VERY LIKELY TO BE CORRUPTED AND LOST FOREVER, OPTIMIZATIONS HAVE NOT BEEN MADE, AND IT IS NOT YET A DEPENDABLE PRODUCT. YOU HAVE BEEN WARNED.


Ok so in this portion of the pre-codec, we have a very specific problem that we would like to solve using a particular technique. Whereas in the general pre-codec that everything will go into later there is a 'latice' technique for isolating all but 1 number from the trailing positions in a 'modified_character', and the trained decoder will have specific knowledge on small words or words that may be numbers, the primary technique in this 'pre-codec' will be providing 'categorization_clues' based on manipulating large (int) and their related (str). In the main program you will notice that if you provide an AI with the numbers in order as a kind of key along with the word key and possibly the huffman code header, it will decode the ambiguous pre-coded document perfectly. (It will even do this without any key at all!) Unfortunately, in documents that consist mostly of numbers this does not improve compression, but reduces it by half (pretty funny). So, in order to solve this we will apply a similar principle to the main program -- the numbers will be narrowed down using a code which provides the AI with a sort of "game". The pre-coder will provide the AI with a variety of boolean flags with associated conditionals, generated by a regular program. It will then write them into a 'number_key' which is packaged with the rest of the pre-coded document. The AI will have access to an API which contains the definitions of the flags and associated conditionals. You can think of this in terms of a lossy form of run length encoding.

Foresight: Likely, compression will be limited to 'blocks' at a time, of a certain size, because of hardware limitations and also the current limitations of AI itself. This is also an area that will probably require signifigant debugging before it could be considered a reliable way to compress and retrieve numbers. Still, it should be easily possible to reliably decompress numerical data using machine inference, given the correct process.

Update: Implementing feedback loop into number.key. when decrypting the document, the AI can determine where some of the numbers go based on the context of the document. It can then extend the truth table to a signifigant extent in some cases. It will have 'set' the pins inbetween the keyway and cylinder, so to speak. It can succesfully narrow down the possible number much more easily when any given integer is certain. 
